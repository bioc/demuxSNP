---
title: "Demultiplexing_using_supervised_learning_with_cell_hashing_and_SNPs"
author:
  - name: Michael Lynch, University of Limerick
  - name: Aedin Culhane, University of Limerick
output:
  BiocStyle::html_document:
    toc_float: true
bibliography: references.bib
vignette: |
  %\VignetteIndexEntry{dim reduction with corral}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  
---

```{r, include = FALSE}
knitr::opts_chunk$set(
    collapse = TRUE,
    comment = "#>",
    message = FALSE,
    fig.width = 7.5
)
```




```{r }

library(SNPcheck)
library(ComplexHeatmap)
library(viridisLite)
library(Seurat)
library(ggpubr)
library(dittoSeq)
library(utils)

```

````{r}
colors <- structure(viridis(n = 3), names = c("-1", "0", "1"))
````

# Introduction

Demultiplexing in scRNAseq involves assigning cells back to their original sample, where cells from different donors, treatment types or physiological locations are sequenced together.
This allows for a significant reduction in cost of sequencing as well as facilitating removal of technical artifacts such as batch effects and multi sample doublets.
To address this need, a large number of methods have been proposed. 
However, a universally robust algorithms remains elusive.
Below, we introduce some existing methods and highlight the novel features of our approach and its advantages to the user.

## Existing methods


### Cell Hashing

Cells from each group are labelled with a distinct tag (HTO or LMO) which is sequenced to give a counts matrix.
Due to non-specific binding, these counts generally form a bimodal distribution.
Such methods are generally computationally efficient.
Their performance, however, is highly dependent on the tagging quality.

Binary vs probabilistic methods

To extend this, recent methods now attempt to probabilistically model this process, allowing users to define a cut-off threshold for the assignment confidence.
While these methods give the user greater flexibility in determinng which cells to keep, the question remains as to what an appropriate value for a sensible cut off is.
This also results in the removal of potentially high quality, valuable cells from downstream analysis.

@boggy_bff_2022

@stoeckius_cell_2018

@kim_citefuse_2020



### SNPs

The second class of methods exploits natural genetic variation between cells and so can only be used where the groups are genetically distinct.
Demuxlet @kang_multiplexed_2018 -high accuracy but requires genotype information
Souporcell @heaton_souporcell_2020 and Vireo @huang_vireo_2019
The performance of these methods is reduced by the presence of ambient RNA and unequal donor contributions.

Demuxlet remains the standard used to benchmark other methods.

## Motivation

Here, we aim to leverage information from both modalities to optimise classification and minimise waste.
We note that as with other SNP based methods, genetic difference between sampe groups is a prerequisite, as well as sufficient sequencing depth.

Novel features:

* Uses both cell hashing and SNP data. 
Current methods are limited to using either the cell hashing counts or SNP calls.
By using a supervised approach, performance increases in classification, particularly when cell contributions are unevenly distributed.
* Selects SNPs based on gene expression to reduce noise and computational cost.
This reduces artifacts caused by cell-type and speeds things up.



## Installation

````{r eval=FALSE}

devtools::install_github("michaelplynch/SNPcheck", build_vignettes = TRUE)

browseVignettes(package="SNPcheck")

````

## Quick Usage

````{r eval=FALSE}
# subset common variants file:
top_genes<-common_genes(sce)
small_vcf<-subset_vcf(sce,vcf)

# create training (high confidence) data
sce<-consensus_calls(sce)

## Reassignment
sce<-add_snps(sce,mat)
sce<-reassign(sce)

````

# Exploratory analysis

We load three data objects. 
A SingleCellExperiment object containing RNA and HTO counts, a vcf file containing SNPs and a matrix containing SNP information for each cell (we will show you how to generate this SNPs matrix using VarTrix outside of R).

````{r}
data(sce,vcf,snps,package="SNPcheck")
````

The HTO or LMO distribution is usually bimodal, with a signal (high counts) and background distribution (low counts) caused by non-specific binding.
Ideally, these distributions would be clearly separated with no overlap, but in practice, this is not always the  case.
in our example data, we see that the signal and noise overlap to varying extents in each Hashtag.

````{r echo=FALSE, warning=FALSE, fig.height=4,fig.width=7.5}
htos <- as.data.frame(t(as.matrix(log(counts(altExp(sce, "HTO"))))))

x1 <- gghistogram(htos, x = "Hashtag1", fill = dittoColors(1)[1], palette = "lancet", xlim = c(0, 10), ylim = c(0, 1000), alpha = 1)
x2 <- gghistogram(htos, x = "Hashtag2", fill = dittoColors(1)[2], palette = "lancet", xlim = c(0, 10), ylim = c(0, 1000), alpha = 1)
x3 <- gghistogram(htos, x = "Hashtag3", fill = dittoColors(1)[3], palette = "lancet", xlim = c(0, 10), ylim = c(0, 1000), alpha = 1)
x4 <- gghistogram(htos, x = "Hashtag4", fill = dittoColors(1)[4], palette = "lancet", xlim = c(0, 10), ylim = c(0, 1000), alpha = 1)
x5 <- gghistogram(htos, x = "Hashtag5", fill = dittoColors(1)[5], palette = "lancet", xlim = c(0, 10), ylim = c(0, 1000), alpha = 1)
x6 <- gghistogram(htos, x = "Hashtag6", fill = dittoColors(1)[6], palette = "lancet", xlim = c(0, 10), ylim = c(0, 1000), alpha = 1)

ggarrange(x1, x2, x3, x4, x5, x6, align = "hv", ncol = 3, nrow = 2)
````

As an example, we will run HTODemux on the data.

````{r}
seurat <- as.Seurat(sce,data=NULL)
seurat <- HTODemux(seurat)
seurat$hash.ID <- factor(as.character(seurat$hash.ID))
sce$seurat <- seurat$hash.ID

sce$seurat <- seurat$hash.ID

table(sce$seurat)
````

Here, we see an unusually large number of cells being called as "Negative".

Additionally, the library size of the "Negative" group looks similar to that of other groups.


````{r}
seurat$libsize <- colSums(GetAssayData(seurat,slot="counts",assay="RNA"))
dittoPlot(seurat, "libsize", group.by = "hash.ID")
````

For the remainder of this vignette we'll outline our method of checking whether or not cells have been called correctly and how to assign them to their appropriate group!

# Preprocessing

Common variants files, for example from the 1000 Genomes Project, can contain over 7 million SNPs.
To reduce computational cost and cell-type effects, we subset our SNPs list to those located within genes expressed across most cells in our data.

We first find the most commonly expressed genes in our RNA data, then subset the vcf file to SNPs seen in those genes.

````{r}
top_genes <- common_genes(sce = sce)

ensdb<-EnsDb.Hsapiens.v86::EnsDb.Hsapiens.v86
subset_vcf(vcf, top_genes = top_genes,ensdb)
````

Next, we wish to identify cells which we can confidently call to a particular group.
There are a number of ways this can be achieved, including probabilistic modelling of the HTO counts, manually setting non-conservative thresholds or using consensus calls. 
Here we have used demuxmix, a probabilistic model which we have set with a high acceptance threshold to generate training data (cells which we can confidently call as a particular singlet group).

````{r }
sce <- consensus_calls(sce)
````

# Variant Calling (VarTrix)

Variant calling is not done within the package. 
Instead, we refer the reader to VarTrix, where they can use the subsetted .vcf file along with their .bam, barcodes.tsv and reference genome to call SNPs.

A sample VarTrix command looks like the following:

````{bash eval=FALSE}

./vartrix -v <path_to_input_vcf> -b <path_to_cellranger_bam> -f <path_to_fasta_file> -c <path_to_cell_barcodes_file> -o <path_for_output_matrix>

````

Using the output matrix from Vartrix and the classifications from the HTO algorithm, we train a knn supervised learning algorithm.

# Cell reassignment, visualisation and evaluation

To keep things tidy, we will add the SNP data to our SingleCellExperiment object as an AlternativeExperiment.
This function also filters out SNPs which are observed at a low frequency in the data.


````{r}

sce <- add_snps(sce, snps, thresh = 0.95)

altExp(sce, "SNP")

````

Before we reassign any cells, we will first visualise the results from individual algorithms.
Below, we compare Seurat and CiteFuse classification. 
Most of the uncertainty here lies between whether a cell is a Singlet/Doublet or Negative rather than which Hashtag.

Splitting the SNP data by Seurat classification, we initially see a large number of 'negative' cells which appear of good quality (high proportion of reads) which may be assignable to another hashtag.
This is consistent with the library size plot we visualised earlier.


````{r}
test <- Heatmap(counts(altExp(sce, "SNP")), 
                column_split = sce$seurat, 
                cluster_rows = FALSE, 
                show_column_names = FALSE, 
                cluster_column_slices = FALSE, 
                column_title_rot = -45, 
                row_title = "SNPs", 
                col = colors)

draw(test,column_title="SNP profiles split by Seurat Hashtag call")
````

````{r}
````

````{r}
sce <- reassign(sce, k = 5)

table(sce$knn)
````


````{r}
test <- Heatmap(counts(altExp(sce, "SNP")),
                column_split = sce$knn, 
                cluster_rows = FALSE, 
                show_column_names = FALSE, 
                cluster_column_slices = FALSE, 
                column_names_rot = 45, 
                column_title_rot = -45, 
                row_title = "SNPs", 
                col = colors)

draw(test,column_title="SNP profiles split by updated knn classification")
````

Focusing in on the new Hashtag5 group, we see that a lot of the Negative cells have now been reclassed to this group, as well as a small number of cells from other groups.

````{r}
test <- Heatmap(counts(altExp(sce, "SNP"))[, sce$knn == "Hashtag5"], 
                column_split = sce$seurat[sce$knn == "Hashtag5"], 
                cluster_rows = FALSE, 
                show_column_names = FALSE, 
                cluster_column_slices = FALSE, 
                column_names_rot = 45, 
                column_title_rot = -45, 
                row_title = "SNPs", 
                col = colors)

draw(test,column_title("knn Hashtag5 group split by original Seurat classification"))
````

## Majority Voting

Should be robust to errors in training data?


````{r}



````

# Session Info

````{r}
sessionInfo()
````

# References
