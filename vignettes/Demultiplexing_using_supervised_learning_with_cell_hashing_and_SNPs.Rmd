---
title: "Demultiplexing_using_supervised_learning_with_cell_hashing_and_SNPs"
author:
  - name: Michael Lynch
    affiliation: University of Limerick
  - name: Aedin Culhane
    affiliation: University of Limerick
output:
  BiocStyle::html_document:
    toc_float: true
bibliography: references.bib
vignette: |
  %\VignetteIndexEntry{dim reduction with corral}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  
---

```{r, include = FALSE}
knitr::opts_chunk$set(
    collapse = TRUE,
    comment = "#>",
    message = FALSE,
    fig.width = 7.5
)
```




```{r }

library(SNPcheck)
library(ComplexHeatmap)
library(viridisLite)
library(Seurat)
library(ggpubr)
library(dittoSeq)
library(utils)

```

````{r}
colors <- structure(viridis(n = 3), names = c("-1", "0", "1"))
````

# Introduction

Multiplexing in scRNAseq means sequencing samples from different patients, treatment types or physiological locations together, resulting in significant cost savings. 
Demultiplexing then involves assigning cells back to their original sample.

To address this need, a large number of methods have been proposed. 
However, a universally robust algorithms remains elusive.
Below, we introduce some existing methods and highlight the novel features of our approach and its advantages to the user.

## Existing methods


### Cell Hashing

Cells from each group are labelled with a distinct tag (HTO or LMO) which is sequenced to give a counts matrix.
Due to non-specific binding, these counts generally form a bimodal distribution.
Such methods are generally computationally efficient.
Their performance, however, is highly dependent on the tagging quality.

More recent methods, including [demuxmix](https://bioconductor.org/packages/release/bioc/html/demuxmix.html), now attempt to probabilistically model this process, allowing users to define a cut-off threshold for the assignment confidence.
While these methods give the user greater flexibility in determining which cells to keep, the question remains as to what a sensible cut off value is.
This also results in the removal of cells due to poor hashing quality rather than RNA quality.

@boggy_bff_2022

@stoeckius_cell_2018

@kim_citefuse_2020



### SNPs

The second class of methods exploits natural genetic variation between cells and so can only be used where the groups are genetically distinct.
Demuxlet @kang_multiplexed_2018 uses genotype information from each group to classify samples.
To address this, Souporcell @heaton_souporcell_2020 and Vireo @huang_vireo_2019 were developed to classify cells without genotype information.
The performance of these methods is reduced by the presence of ambient RNA and unequal donor contributions.

Demuxlet remains the standard used to benchmark other methods but its more widespread adoption has been limited by the requirement of sample genotype information.

## Motivation

**With cell hashing, we can confidently demultiplex *some* but not *all* cells.
Using these high confidence cells, we can learn the SNPs associated with each group.
This information can then be used to assign remaining cells (which we could not confidently call using cell hashing) to their most similar group based on their SNP profile.**

Novel features:

* Uses both cell hashing and SNP data. 
Current methods are limited to using either the cell hashing counts or SNP calls.
By using a supervised approach, performance increases in classification relative to unsupervised SNP approaches, particularly when cell contributions are unevenly distributed.
* Selects SNPs based on gene expression to reduce noise and computational cost.

Impact:

* Users can visually confirm validity (or lack thereof) of existing demultiplexing results in a tangible manner.
* Users can recover otherwise high quality cells which could not be confidently assigned using other methods.

## Installation

````{r eval=FALSE}

devtools::install_github("michaelplynch/SNPcheck", build_vignettes = TRUE)

browseVignettes(package="SNPcheck")

````

## Quick Usage

````{r eval=FALSE}
# subset common variants file:
top_genes<-common_genes(sce)
small_vcf<-subset_vcf(sce,vcf)

# create training (high confidence) data
sce<-consensus_calls(sce)

## Reassignment
sce<-add_snps(sce,mat)
sce<-reassign(sce)

````

## Function explanation

````{r eval=FALSE}

top_genes<-common_genes(sce)

````

This function returns the genes which are expressed (expression > 0) in the highest proportion of cells.
These genes are used below to subset the vcf file.

````{r eval=FALSE}

subset_vcf(vcf, top_geens, ensdb)

````

This function subsets a supplied vcf to SNP locations within the genes supplied. 
The ranges of the genes are extracted from the EnsDb object.

````{r eval=FALSE}

sce<-consensus_calls(sce)

````

This function takes a SingleCellExperiment object with HTO altExp, runs [demuxmix](https://bioconductor.org/packages/release/bioc/html/demuxmix.html) and returns a vector of assigned labels.

````{r eval=FALSE}

sce<-add_snps(sce,snps)

````

Adds the SNP data to the SingleCellExperiment object as an altExp.
Additionally, filteres out SNPs with no reads in less than 'thresh' proportion of cells.

````{r eval=FALSE}

sce<-reassign(sce)

````

Reassignment based on SNP profiles of high confidence cells.
Singlet training data is based on high confidence singlet assignment.
To simulate doublets in the training data, we systematically sample and combine n cells pairs from each grouping combination.


# Exploratory analysis

We load three data objects. 
A SingleCellExperiment object containing RNA and HTO counts, a vcf file containing SNPs and a matrix containing SNP information for each cell (we will show you how to generate this SNPs matrix using VarTrix outside of R).

````{r}
data(sce,vcf,snps,package="SNPcheck")
````

The HTO or LMO distribution is usually bimodal, with a signal (high counts) and background distribution (low counts) caused by non-specific binding.
Ideally, these distributions would be clearly separated with no overlap, but in practice, this is not always the  case.
in our example data, we see that the signal and noise overlap to varying extents in each Hashtag.

````{r echo=FALSE, warning=FALSE, fig.height=4,fig.width=7.5}
htos <- as.data.frame(t(as.matrix(log(counts(altExp(sce, "HTO"))))))

x1 <- gghistogram(htos, x = "Hashtag1", fill = dittoColors(1)[1], palette = "lancet", xlim = c(0, 10), ylim = c(0, 1000), alpha = 1)
x2 <- gghistogram(htos, x = "Hashtag2", fill = dittoColors(1)[2], palette = "lancet", xlim = c(0, 10), ylim = c(0, 1000), alpha = 1)
x3 <- gghistogram(htos, x = "Hashtag3", fill = dittoColors(1)[3], palette = "lancet", xlim = c(0, 10), ylim = c(0, 1000), alpha = 1)
x4 <- gghistogram(htos, x = "Hashtag4", fill = dittoColors(1)[4], palette = "lancet", xlim = c(0, 10), ylim = c(0, 1000), alpha = 1)
x5 <- gghistogram(htos, x = "Hashtag5", fill = dittoColors(1)[5], palette = "lancet", xlim = c(0, 10), ylim = c(0, 1000), alpha = 1)
x6 <- gghistogram(htos, x = "Hashtag6", fill = dittoColors(1)[6], palette = "lancet", xlim = c(0, 10), ylim = c(0, 1000), alpha = 1)

ggarrange(x1, x2, x3, x4, x5, x6, align = "hv", ncol = 3, nrow = 2)
````

As an example, we will run HTODemux on the data.

````{r}
seurat <- as.Seurat(sce,data=NULL)
seurat <- HTODemux(seurat)
seurat$hash.ID <- factor(as.character(seurat$hash.ID))
sce$seurat <- seurat$hash.ID

sce$seurat <- seurat$hash.ID

table(sce$seurat)
````

Here, we see an unusually large number of cells being called as "Negative".

Additionally, the library size of the "Negative" group looks similar to that of other groups.


````{r}
seurat$libsize <- colSums(GetAssayData(seurat,slot="counts",assay="RNA"))
dittoPlot(seurat, "libsize", group.by = "hash.ID")
````

For the remainder of this vignette we'll outline our method of checking whether or not cells have been called correctly and how to assign them to their appropriate group!

# Preprocessing

Common variants files, for example from the 1000 Genomes Project, can contain over 7 million SNPs.
To reduce computational cost and cell-type effects, we subset our SNPs list to those located within genes expressed across most cells in our data.

We first find the most commonly expressed genes in our RNA data.

````{r}
top_genes <- common_genes(sce = sce)

top_genes[1:10]

````

We have a sample vcf preloaded, but you can load a vcf file in using readVcf()

````{r eval=FALSE}

vcf<-readVcf('filepath',genome="GRCh38")

````

We will subset our vcf file to SNPs seen in our commonly expressed genes.
Notice that the genome for the vcf and EnsDb object must be compatible!

The returned vcf can be written to file and used with VarTrix later on.

````{r}
ensdb<-EnsDb.Hsapiens.v86::EnsDb.Hsapiens.v86

seqinfo(vcf)@genome[1]==seqinfo(ensdb)@genome[1]

subset_vcf(vcf, top_genes = top_genes,ensdb)
````

Next, we wish to identify cells which we can confidently call to a particular group.
There are a number of ways this can be achieved, including probabilistic modelling of the HTO counts, manually setting non-conservative thresholds or using consensus calls. 
Here we have used [demuxmix](https://bioconductor.org/packages/release/bioc/html/demuxmix.html), a probabilistic model which we have set with a high acceptance threshold to identify high confidence cell calls to use as training data (cells which we can confidently call as a particular singlet group).

````{r }
sce <- consensus_calls(sce)

table(sce$train)
````

# Variant Calling (VarTrix)

Variant calling is not done within the package. 
Instead, we refer the reader to VarTrix, where they can use the subsetted .vcf file along with their .bam, barcodes.tsv and reference genome to call SNPs.

A sample VarTrix command looks like the following:

````{bash eval=FALSE}

./vartrix -v <path_to_input_vcf> -b <path_to_cellranger_bam> -f <path_to_fasta_file> -c <path_to_cell_barcodes_file> -o <path_for_output_matrix>

````

Using the output matrix from Vartrix and the classifications from the HTO algorithm, we train a knn supervised learning algorithm.

# Cell reassignment, visualisation and evaluation

To keep things tidy, we will add the SNP data to our SingleCellExperiment object as an alternative Experiment.
This function also filters out SNPs which are observed at a low frequency in the data, and the threshold can be set manually.


````{r}

dim(snps)

sce <- add_snps(sce, snps, thresh = 0.95)

altExp(sce, "SNP")

````

Before we reassign any cells, we will first visualise the results from individual algorithms.

Splitting the SNP data by Seurat classification, we initially see a large number of 'negative' cells which appear of good quality (high proportion of reads) which may be assignable to another hashtag.
This is consistent with the library size plot we visualised earlier.


````{r}
test <- Heatmap(counts(altExp(sce, "SNP")), 
                column_split = sce$seurat, 
                cluster_rows = FALSE, 
                show_column_names = FALSE, 
                cluster_column_slices = FALSE, 
                column_title_rot = -45, 
                row_title = "SNPs", 
                col = colors)

draw(test,column_title="SNP profiles split by Seurat Hashtag call")
````

````{r}
````

````{r}
sce <- reassign(sce, k = 5)

table(sce$knn)
````


````{r}
test <- Heatmap(counts(altExp(sce, "SNP")),
                column_split = sce$knn, 
                cluster_rows = FALSE, 
                show_column_names = FALSE, 
                cluster_column_slices = FALSE, 
                column_names_rot = 45, 
                column_title_rot = -45, 
                row_title = "SNPs", 
                col = colors)

draw(test,column_title="SNP profiles split by updated knn classification")
````

Focusing in on the new Hashtag5 group, we see that a lot of the Negative cells have now been reclassed to this group, as well as a small number of cells from other groups.

````{r}
test <- Heatmap(counts(altExp(sce, "SNP"))[, sce$knn == "Hashtag5"], 
                column_split = sce$seurat[sce$knn == "Hashtag5"], 
                cluster_rows = FALSE, 
                show_column_names = FALSE, 
                cluster_column_slices = FALSE, 
                column_names_rot = 45, 
                column_title_rot = -45, 
                row_title = "SNPs", 
                col = colors)

draw(test,column_title="knn Hashtag5 group split by original Seurat classification")
````

## Majority Voting

Should be robust to errors in training data?


````{r}



````

# Session Info

````{r}
sessionInfo()
````

# References
